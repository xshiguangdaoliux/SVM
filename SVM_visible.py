import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split #sklearn: æä¾›å·¥å…·ç”¨äºæ•°æ®åˆ’åˆ†ã€æ ‡å‡†åŒ–å’Œè¯„ä¼°ã€‚
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import matplotlib
matplotlib.use('TkAgg')  # ä½¿ç”¨ TkAgg åç«¯ï¼ˆéœ€è¦å®‰è£… tkinterï¼‰
import matplotlib.pyplot as plt
# è®¾ç½®å­—ä½“ä¸º SimHeiï¼ˆé»‘ä½“ï¼‰ï¼Œæ”¯æŒä¸­æ–‡
plt.rcParams['font.sans-serif'] = ['SimHei']  # ä½¿ç”¨é»‘ä½“
plt.rcParams['axes.unicode_minus'] = False   # æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
import torch #torch: PyTorch æ˜¯æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºå®šä¹‰æ¨¡å‹ã€è®­ç»ƒå’Œè¯„ä¼°ã€‚
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset

# æ•°æ®æ¥æº: å¨æ–¯åº·æ˜Ÿå·ä¹³è…ºç™Œæ•°æ®é›†ï¼ŒåŒ…å«è‚¿ç˜¤ç‰¹å¾å’Œè¯Šæ–­ç»“æœã€‚
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data"
data = pd.read_csv(url, header=None)


"""X: æ•°æ®çš„ç‰¹å¾éƒ¨åˆ†ï¼Œä»ç¬¬ 3 åˆ—å¼€å§‹åˆ°æœ€åä¸€åˆ—ï¼ˆå‰ä¸¤åˆ—æ˜¯ ID å’Œè¯Šæ–­æ ‡ç­¾ï¼‰ã€‚
y: ç›®æ ‡å˜é‡ï¼Œç¬¬äºŒåˆ—ä¸ºè¯Šæ–­ç»“æœï¼ŒåŒ…å«ä¸¤ç±»ï¼š
M: æ¶æ€§ (Malignant)
B: è‰¯æ€§ (Benign)"""
X = data.iloc[:, 2:].values
y = data.iloc[:, 1].values

"""å°†ç›®æ ‡å˜é‡ y è½¬æ¢ä¸ºæ•°å€¼å½¢å¼ï¼š
1: æ¶æ€§ (M)
-1: è‰¯æ€§ (B)
np.where: æ¡ä»¶å‡½æ•°ï¼Œæ»¡è¶³ y == 'M' çš„å…ƒç´ èµ‹å€¼ä¸º 1ï¼Œå¦åˆ™ä¸º -1ã€‚"""
y = np.where(y == 'M', 1, -1)
"""ä¸ºäº†æ–¹ä¾¿å¯è§†åŒ–ï¼Œåªé€‰æ‹©å‰ä¸¤ä¸ªç‰¹å¾ï¼ˆradius_mean å’Œ texture_meanï¼‰ã€‚
åŸå§‹æ•°æ®é›†ä¸­æœ‰ 30 ä¸ªç‰¹å¾ï¼Œä½†åœ¨äºŒç»´å¹³é¢ä¸­æ— æ³•ç›´æ¥å¯è§†åŒ–ã€‚"""
X = X[:, :2]
"""train_test_split: å°†æ•°æ®åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚
test_size=0.2: æµ‹è¯•é›†å  20%ã€‚
random_state=42: è®¾ç½®éšæœºç§å­ï¼Œä¿è¯ç»“æœå¯é‡å¤ã€‚
è¿”å›ç»“æœï¼š
X_train å’Œ X_test: è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„ç‰¹å¾ã€‚
y_train å’Œ y_test: è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„ç›®æ ‡å˜é‡ã€‚
"""
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""æ ‡å‡†åŒ–: å¯¹æ•°æ®è¿›è¡Œå½’ä¸€åŒ–å¤„ç†ï¼Œä½¿æ¯ä¸ªç‰¹å¾å…·æœ‰é›¶å‡å€¼å’Œå•ä½æ–¹å·®ã€‚è¿™å¯¹æ”¯æŒå‘é‡æœº (SVM) ç­‰æ¨¡å‹è‡³å…³é‡è¦ï¼Œå› ä¸ºå®ƒä»¬å¯¹ç‰¹å¾çš„å°ºåº¦æ•æ„Ÿã€‚"""
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""torch.tensor: å°† NumPy æ•°ç»„è½¬æ¢ä¸º PyTorch å¼ é‡ã€‚
dtype=torch.float32: æ•°æ®ç±»å‹ä¸º 32 ä½æµ®ç‚¹æ•°ã€‚
view(-1, 1): å°†ç›®æ ‡å˜é‡ y è½¬æ¢ä¸ºäºŒç»´å¼ é‡ï¼Œæ–¹ä¾¿åç»­çŸ©é˜µè¿ç®—ã€‚
"""
X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)
X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)
"""TensorDataset: å°†ç‰¹å¾å’Œç›®æ ‡å˜é‡å°è£…ä¸º PyTorch æ•°æ®é›†å¯¹è±¡ã€‚
DataLoader: å°†æ•°æ®é›†åˆ†æˆå°æ‰¹æ¬¡ï¼Œç”¨äºè®­ç»ƒï¼š
batch_size=32: æ¯æ‰¹æ•°æ®åŒ…å« 32 ä¸ªæ ·æœ¬ã€‚
shuffle=True: åœ¨æ¯ä¸ª epoch ä¹‹å‰å¯¹æ•°æ®è¿›è¡Œéšæœºæ‰“ä¹±ï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚"""
train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

"""LinearSVM ç±»:
è¿™æ˜¯ä¸€ä¸ªè‡ªå®šä¹‰çš„ PyTorch æ¨¡å‹ï¼Œç”¨äºå®ç°çº¿æ€§æ”¯æŒå‘é‡æœº (SVM)ã€‚"""
"""__init__ æ–¹æ³•:

å‚æ•° input_dim: è¾“å…¥ç‰¹å¾çš„ç»´åº¦å¤§å°ï¼ˆå³ç‰¹å¾æ•°é‡ï¼‰ã€‚
self.fc: å®šä¹‰äº†ä¸€ä¸ªå…¨è¿æ¥å±‚ (nn.Linear)ã€‚
input_dim: è¾“å…¥ç‰¹å¾æ•°é‡ã€‚
1: è¾“å‡ºä¸€ä¸ªæ ‡é‡å€¼ï¼Œç”¨äºäºŒåˆ†ç±»ä»»åŠ¡ã€‚
bias=False: ä¸ä½¿ç”¨åç½®é¡¹ï¼Œå› ä¸ºçº¿æ€§ SVM çš„åˆ†ç±»è¶…å¹³é¢åªéœ€è¦æƒé‡ï¼Œä¸éœ€è¦åç½®é¡¹ã€‚
forward æ–¹æ³•:

æ¥æ”¶è¾“å…¥ xï¼ˆç‰¹å¾å‘é‡ï¼‰ï¼Œé€šè¿‡å…¨è¿æ¥å±‚è®¡ç®—ç»“æœ self.fc(x)ã€‚
è¾“å‡ºæ˜¯ä¸€ä¸ªæ ‡é‡å€¼ï¼Œè¡¨ç¤ºè¾“å…¥æ ·æœ¬åˆ°è¶…å¹³é¢çš„è·ç¦»ã€‚"""

class LinearSVM(nn.Module):
    def __init__(self, input_dim):
        super(LinearSVM, self).__init__()
        self.fc = nn.Linear(input_dim, 1, bias=False)  # No bias term for SVM

    def forward(self, x):
        return self.fc(x)

"""HingeLoss ç±»:
è‡ªå®šä¹‰çš„ Hinge Loss å‡½æ•°ï¼Œç”¨äºè®­ç»ƒæ”¯æŒå‘é‡æœºã€‚
ç»§æ‰¿è‡ª torch.nn.Module"""
class HingeLoss(nn.Module):
    def forward(self, outputs, targets):
        hinge_loss = torch.clamp(1 - outputs * targets, min=0)
        return torch.mean(hinge_loss)

"""input_dim: è¾“å…¥ç‰¹å¾çš„ç»´åº¦å¤§å°ï¼ˆç­‰äº X_train çš„åˆ—æ•°ï¼Œå³æ‰€é€‰çš„ç‰¹å¾æ•°é‡ï¼‰ã€‚
model:
ä½¿ç”¨ LinearSVM ç±»åˆå§‹åŒ–æ¨¡å‹ã€‚
æ¨¡å‹å°†æ¥å—ç‰¹å¾å‘é‡ä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºä¸€ä¸ªæ ‡é‡å€¼"""
input_dim = X_train.shape[1]
model = LinearSVM(input_dim)

"""ä¼˜åŒ–å™¨ (optimizer):
ä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆSGDï¼‰ä¼˜åŒ–å™¨ï¼š
model.parameters(): éœ€è¦ä¼˜åŒ–çš„æ¨¡å‹å‚æ•°ï¼ˆçº¿æ€§å±‚çš„æƒé‡ï¼‰ã€‚
lr=0.1: å­¦ä¹ ç‡ï¼Œæ§åˆ¶æ¯æ¬¡å‚æ•°æ›´æ–°çš„æ­¥é•¿ã€‚
weight_decay=0.01: L2 æ­£åˆ™åŒ–é¡¹ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œç›¸å½“äº SVM ä¸­çš„æ­£åˆ™åŒ–å‚æ•° 
ğ¶"""
criterion = HingeLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.1, weight_decay=0.01)  # L2 regularization as weight decay

"""å¼€å§‹å®é™…çš„è®­ç»ƒäº†"""
num_epochs = 50
for epoch in range(num_epochs):
    model.train()
    epoch_loss = 0.0
    for X_batch, y_batch in train_loader:
        """outputs = model(X_batch): ä½¿ç”¨çº¿æ€§ SVM æ¨¡å‹å¯¹è¾“å…¥ X_batch è¿›è¡Œé¢„æµ‹ã€‚
loss = criterion(outputs, y_batch): è®¡ç®—é¢„æµ‹å€¼ä¸çœŸå®æ ‡ç­¾çš„ Hinge Loss"""
        outputs = model(X_batch)
        loss = criterion(outputs, y_batch)

        # Backward pass and optimization
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        epoch_loss += loss.item()

    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss / len(train_loader):.4f}")

"""model.eval():
å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼Œå…³é—­ dropout å’Œ batch normalization ç­‰è¡Œä¸ºï¼Œç¡®ä¿é¢„æµ‹ç¨³å®šã€‚
torch.no_grad():
ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ŒåŠ å¿«æ¨ç†é€Ÿåº¦å¹¶èŠ‚çœæ˜¾å­˜ã€‚"""
model.eval()
with torch.no_grad():
    y_test_pred = model(X_test_tensor)
    y_test_pred = torch.sign(y_test_pred).view(-1).numpy()

print("Accuracy:", accuracy_score(y_test, y_test_pred))
print("Classification Report:\n", classification_report(y_test, y_test_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_test_pred))

"""å®šä¹‰ç»˜å›¾çš„èŒƒå›´ï¼š
x_min, x_max å’Œ y_min, y_max: ç¡®å®šç‰¹å¾ radius_mean å’Œ texture_mean çš„å€¼åŸŸèŒƒå›´ï¼Œå¹¶æ‰©å±•ä¸€å®šçš„è¾¹è·ã€‚
ç”Ÿæˆç½‘æ ¼ç‚¹ï¼š
np.meshgrid: åœ¨æŒ‡å®šèŒƒå›´å†…ç”ŸæˆäºŒç»´ç½‘æ ¼ï¼Œç”¨äºå¯è§†åŒ–å†³ç­–è¾¹ç•Œã€‚"""
x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))

grid = np.c_[xx.ravel(), yy.ravel()]
grid_tensor = torch.tensor(scaler.transform(grid), dtype=torch.float32)

with torch.no_grad():
    Z = model(grid_tensor).view(-1).numpy()
    Z = Z.reshape(xx.shape)
"""ç»˜åˆ¶å†³ç­–è¾¹ç•Œ"""
plt.figure(figsize=(10, 6))
plt.contourf(xx, yy, Z, levels=[-1, 0, 1], alpha=0.8, colors=["#FFAAAA", "#AAAAFF", "#AAFFAA"])
plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdYlGn, edgecolor="k")
plt.title("è‰¯æ¶æ€§ä¹³è…ºç™Œ - æ”¯æŒå‘é‡æœº")
plt.xlabel("radius_mean")
plt.ylabel("texture_mean")
plt.show()
